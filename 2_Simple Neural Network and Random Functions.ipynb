{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neural Networks\n",
    "Mathematically this looks like:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &amp;= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &amp;= f\\left(\\sum_i w_i x_i +b \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "With vectors this is the dot/inner product of two vectors:\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots  x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_1 \\\\\n",
    "           w_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           w_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "## Tensors\n",
    "It turns out neural network computations are just a bunch of linear algebra operations on tensors, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.\n",
    "\n",
    "### Reshaping Tensors\n",
    "There are a few options here: weights.reshape(), weights.resize_(), and weights.view().\n",
    "\n",
    "- weights.reshape(a, b) will return a new tensor with the same data as weights with size (a, b) sometimes, and sometimes a clone, as in it copies the data to another part of memory.\n",
    "\n",
    "- weights.resize_(a, b) returns the same tensor with a different shape. However, if the new shape results in fewer elements than the original tensor, some elements will be removed from the tensor (but not from memory). If the new shape results in more elements than the original tensor, new elements will be uninitialized in memory. Here I should note that the underscore at the end of the method denotes that this method is performed in-place. Here is a great forum thread to read more about in-place operations in PyTorch.\n",
    "\n",
    "- weights.view(a, b) will return a new tensor with the same data as weights with size (a, b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+ torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate some data\n",
    "torch.manual_seed(7) #set the random seeds so things are predictible\n",
    "\n",
    "#Features are 5 random normal varables , 1 row 5 columns\n",
    "features = torch.randn((1,5))\n",
    "#True weights for our data , random normal variables again , weights created of same shape as features\n",
    "weights = torch.rand_like(features)\n",
    "#Bias term\n",
    "bias = torch.randn((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6140]])\n"
     ]
    }
   ],
   "source": [
    "#Output of network\n",
    "y = activation(torch.sum(weights*features) + bias)\n",
    "print(y)\n",
    "# y = activation((features*weights).sum + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "#Methods for matrix multiplication\n",
    "    # torch.mm() - strict about shape of tensors \n",
    "    # torch.matmul() - provides output even if shape not appropriate\n",
    "'''\n",
    "torch.mm(weights,features) \n",
    "provides output---  size mismatch, m1: [1 x 5], m2: [1 x 5] \n",
    "'''\n",
    "#To find shape of a tensor - tensor.shape\n",
    "print(weights.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping Tensors\n",
    "# tensor.reshape(), tensor.view() , tensor.resize_()- underscore means it is inplace operation\n",
    "# features.view(5,1) - creates a new tensor have to be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6140]])\n"
     ]
    }
   ],
   "source": [
    "#Output using matrix multiplication \n",
    "y = activation(torch.mm(weights,features.view(5,1)) + bias)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
