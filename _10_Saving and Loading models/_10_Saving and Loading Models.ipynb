{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Saving and Loading Models\n",
    "To load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images = images.resize_(images.size()[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "    \n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            \n",
    "            # Flatten images into a 784 long vector\n",
    "            images.resize_(images.size()[0], 784)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "# Create the network, define the criterion and optimizer\n",
    "modelDeep = Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 2.317..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 1/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.307..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 1/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 1/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 1/5..  Training Loss: 2.316..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.316..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 1/5..  Training Loss: 2.308..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 1/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.315..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.316..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.317..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.308..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.316..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 2/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 3/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.315..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.316..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 3/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 3/5..  Training Loss: 2.315..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 3/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 3/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 3/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 3/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.315..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.316..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 4/5..  Training Loss: 2.316..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 4/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 4/5..  Training Loss: 2.315..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.309..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 5/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.307..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.315..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.308..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.315..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.070\n",
      "Epoch: 5/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.317..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.313..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.311..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.310..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.308..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.314..  Test Loss: 2.308..  Test Accuracy: 0.069\n",
      "Epoch: 5/5..  Training Loss: 2.312..  Test Loss: 2.308..  Test Accuracy: 0.069\n"
     ]
    }
   ],
   "source": [
    "train(modelDeep, trainloader, testloader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Saving and loading networks\n",
    "- The parameters for PyTorch networks are stored in a **model's state_dict**\n",
    "- We can see the state dict contains the weight and bias matrices for each of our layers.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "# model_name.save_dict() contains all parameters and bias list wise\n",
    "print(\"Our model: \\n\\n\", modelDeep, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", modelDeep.state_dict().keys())\n",
    "\n",
    "#Save the state_dict with torch.save\n",
    "#We can save it in a file checkpoint.pth\n",
    "torch.save(modelDeep.state_dict(), 'checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading parameters using torch.load \n",
    "state_dict = torch.load('checkpoint.pth')\n",
    "\n",
    "\n",
    "\n",
    "# initialise new model with random parameters and then replace those by earlier ones\n",
    "\n",
    "#Creating model \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images = images.resize_(images.size()[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "    \n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            \n",
    "            # Flatten images into a 784 long vector\n",
    "            images.resize_(images.size()[0], 784)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "# Create the network, define the criterion and optimizer\n",
    "model = Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading new model with earlier parameters\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1..  Training Loss: 1.737..  Test Loss: 1.014..  Test Accuracy: 0.655\n",
      "Epoch: 1/1..  Training Loss: 1.031..  Test Loss: 0.742..  Test Accuracy: 0.730\n",
      "Epoch: 1/1..  Training Loss: 0.877..  Test Loss: 0.680..  Test Accuracy: 0.745\n",
      "Epoch: 1/1..  Training Loss: 0.769..  Test Loss: 0.630..  Test Accuracy: 0.755\n",
      "Epoch: 1/1..  Training Loss: 0.772..  Test Loss: 0.623..  Test Accuracy: 0.758\n",
      "Epoch: 1/1..  Training Loss: 0.707..  Test Loss: 0.602..  Test Accuracy: 0.774\n",
      "Epoch: 1/1..  Training Loss: 0.680..  Test Loss: 0.586..  Test Accuracy: 0.783\n",
      "Epoch: 1/1..  Training Loss: 0.675..  Test Loss: 0.558..  Test Accuracy: 0.789\n",
      "Epoch: 1/1..  Training Loss: 0.694..  Test Loss: 0.560..  Test Accuracy: 0.792\n",
      "Epoch: 1/1..  Training Loss: 0.666..  Test Loss: 0.539..  Test Accuracy: 0.801\n",
      "Epoch: 1/1..  Training Loss: 0.631..  Test Loss: 0.543..  Test Accuracy: 0.804\n",
      "Epoch: 1/1..  Training Loss: 0.619..  Test Loss: 0.543..  Test Accuracy: 0.794\n",
      "Epoch: 1/1..  Training Loss: 0.612..  Test Loss: 0.513..  Test Accuracy: 0.819\n",
      "Epoch: 1/1..  Training Loss: 0.619..  Test Loss: 0.511..  Test Accuracy: 0.814\n",
      "Epoch: 1/1..  Training Loss: 0.573..  Test Loss: 0.512..  Test Accuracy: 0.807\n",
      "Epoch: 1/1..  Training Loss: 0.596..  Test Loss: 0.495..  Test Accuracy: 0.814\n",
      "Epoch: 1/1..  Training Loss: 0.604..  Test Loss: 0.502..  Test Accuracy: 0.818\n",
      "Epoch: 1/1..  Training Loss: 0.566..  Test Loss: 0.499..  Test Accuracy: 0.823\n",
      "Epoch: 1/1..  Training Loss: 0.565..  Test Loss: 0.497..  Test Accuracy: 0.819\n",
      "Epoch: 1/1..  Training Loss: 0.560..  Test Loss: 0.478..  Test Accuracy: 0.825\n",
      "Epoch: 1/1..  Training Loss: 0.589..  Test Loss: 0.490..  Test Accuracy: 0.826\n",
      "Epoch: 1/1..  Training Loss: 0.549..  Test Loss: 0.499..  Test Accuracy: 0.814\n",
      "Epoch: 1/1..  Training Loss: 0.594..  Test Loss: 0.510..  Test Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "# this models trains with continuation of earlier model \n",
    "# Initial model ended at 70% this continues and ended at 81% accuracy\n",
    "train(model, trainloader, testloader, criterion, optimizer,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above approach only works if architecture of new model is same as earlier model ,so rebuild the new model same as the old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ab13f6ab98c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch-deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
     ]
    }
   ],
   "source": [
    "# Trying over new model architecture\n",
    "# Try this# Try t \n",
    "model2  = Network(784, 10, [400, 200, 100])\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - BETTER APPROACH\n",
    "- This means we need to rebuild the model exactly as it was when trained.\n",
    "- Information about the model architecture needs to be saved in the checkpoint, along with the state dict.\n",
    "- To do this, you build a dictionary with all the information you need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint2.pth')\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model =Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint2.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
