{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Networks\n",
    "\n",
    "**loss function**\n",
    "<img src='https://user-images.githubusercontent.com/24764528/50548756-4ed98d80-0c78-11e9-8ce2-ba646fd7e21b.png' width='400px'></p>\n",
    "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
    "\n",
    "Minimize loss using gradient descent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "<img src='https://user-images.githubusercontent.com/24764528/40543407-d5014d00-6041-11e8-8c77-9524d8922995.gif' width='400px'></p>\n",
    "\n",
    "$$\n",
    "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
    "$$\n",
    "\n",
    "We update our weights using this gradient with some learning rate $\\alpha$.\n",
    "\n",
    "$$\n",
    "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses in PyTorch\n",
    " PyTorch provides losses such as the cross-entropy loss **(nn.CrossEntropyLoss)** assigned to **criterion**.\n",
    " \n",
    " **Note**\n",
    " \n",
    " we need to pass in the raw output of our network into the loss, not the output of the softmax function. This raw output is usually called the logits or scores. We use the logits because softmax gives you probabilities which will often be very close to zero or one but floating-point numbers can't accurately represent values near zero or one. It's usually best to avoid doing calculations with probabilities, typically we use log-probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3596, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Model using raw logits and nn.CrossEntropyLoss\n",
    "model = nn.Sequential(\n",
    "                        nn.Linear(784,128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128,64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64,10)\n",
    "                    )\n",
    "\n",
    "# Define Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get your data\n",
    "images , labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0],-1)\n",
    "\n",
    "# Forward pass get your logits\n",
    "logits = model(images)\n",
    "\n",
    "# Calculate the loss with logits and labels\n",
    "loss = criterion(logits,labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogSoftmax Output \n",
    "it's more convenient to build the model with a **log-softmax** output using **nn.LogSoftmax** or **F.log_softmax** .Get the actual probabilities by taking the exponential torch.exp(output). \n",
    "With a log-softmax output, you want to use the **negative log likelihood loss, nn.NLLLoss**.\n",
    "\n",
    "Note that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2903, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Model using nn.LogSOftmax with error function nn.NLLLoss\n",
    "model = nn.Sequential(\n",
    "                        nn.Linear(784,128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128,64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64,10),\n",
    "                        nn.LogSoftmax(dim =1)\n",
    "                    )\n",
    "\n",
    "# Define Loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get your data\n",
    "images , labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0],-1)\n",
    "\n",
    "# Forward pass get your logits\n",
    "log_probability = model(images)\n",
    "\n",
    "# Calculate the loss with logits and labels\n",
    "loss = criterion(log_probability,labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Autograd\n",
    "\n",
    "- To perform Backpropagation\n",
    "- To automatically calculating the gradients of tensors\n",
    "- calculate the gradients of all our parameters with respect to the loss\n",
    "- Autograd works by keeping track of operations performed on tensors\n",
    "- To make sure PyTorch keeps track of operations on a tensor use **requires_grad = True on a tensor**\n",
    "- At any time do  **x.requires_grad_(True)**\n",
    "- **x.grad** tells value of gradient\n",
    "- **c.grad_fn** shows functin that generated this variable\n",
    "- you can turn on or off gradients altogether with **torch.set_grad_enabled(True|False)**.\n",
    "- You can turn off gradients for a block of code with the torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= tensor([[-1.0055, -0.4734],\n",
      "        [ 0.3397,  1.2363]], requires_grad=True)\n",
      "y= tensor([[1.0111, 0.2241],\n",
      "        [0.1154, 1.5285]], grad_fn=<PowBackward0>)\n",
      "<PowBackward0 object at 0x7f1418ab66a0>\n",
      "None\n",
      "tensor([[-0.5028, -0.2367],\n",
      "        [ 0.1699,  0.6182]])\n",
      "tensor([[-0.5028, -0.2367],\n",
      "        [ 0.1699,  0.6182]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Autograd usage Example\n",
    "# Autograd track tensors for this set requires_grad = true\n",
    "x = torch.randn(2,2,requires_grad = True)\n",
    "y = x ** 2\n",
    "print(\"x=\", x)\n",
    "print(\"y=\", y)\n",
    "# grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)\n",
    "z = y.mean()\n",
    "\n",
    "# To show gradient \n",
    "print(x.grad)\n",
    "# To Calculate gradient \n",
    "z.backward()\n",
    "# Comparing output came and gradient output\n",
    "print(x.grad)\n",
    "print(x/2)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient of x\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loss and Autograd together\n",
    "\n",
    "- When we create a network with PyTorch, all of the parameters are initialized with requires_grad = True.\n",
    "\n",
    "- These gradients are used to update the weights with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[ 9.3826e-06,  9.3826e-06,  9.3826e-06,  ...,  9.3826e-06,\n",
      "          9.3826e-06,  9.3826e-06],\n",
      "        [ 5.9414e-05,  5.9414e-05,  5.9414e-05,  ...,  5.9414e-05,\n",
      "          5.9414e-05,  5.9414e-05],\n",
      "        [-2.9772e-04, -2.9772e-04, -2.9772e-04,  ..., -2.9772e-04,\n",
      "         -2.9772e-04, -2.9772e-04],\n",
      "        ...,\n",
      "        [ 1.1906e-04,  1.1906e-04,  1.1906e-04,  ...,  1.1906e-04,\n",
      "          1.1906e-04,  1.1906e-04],\n",
      "        [ 4.3542e-06,  4.3542e-06,  4.3542e-06,  ...,  4.3542e-06,\n",
      "          4.3542e-06,  4.3542e-06],\n",
      "        [ 2.4861e-04,  2.4861e-04,  2.4861e-04,  ...,  2.4861e-04,\n",
      "          2.4861e-04,  2.4861e-04]])\n"
     ]
    }
   ],
   "source": [
    "# Autograd with Loss to Calculate Gradients\n",
    "\n",
    "model = nn.Sequential(\n",
    "                        nn.Linear(784,128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128,64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64,10),\n",
    "                        nn.Softmax(dim=1)\n",
    "                        )\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get your data\n",
    "images , labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0],-1)\n",
    "\n",
    "loss_prob = model(images)\n",
    "loss = criterion(loss_prob, labels)\n",
    "\n",
    "#Checking gradient of first layer\n",
    "print(model[0].weight.grad)\n",
    "\n",
    "#Generating weights\n",
    "loss.backward()\n",
    "\n",
    "#Output of gradients of first layer\n",
    "print(model[0].weight.grad)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training the network\n",
    "- **optimizer** that we'll use to update the weights with the gradients. We get these from **PyTorch's optim** package.\n",
    "\n",
    "### The general process with PyTorch:\n",
    "\n",
    "- Make a **forward pass** through the network\n",
    "- Use the network **output** to calculate the loss\n",
    "- Perform a **backward pass** through the network with loss.backward() to calculate the gradients\n",
    "- Take a step with the optimizer to **update the weights**\n",
    "\n",
    "-**note**\n",
    "optimizer.zero_grad(). When you do multiple backwards passes with the same parameters, the gradients are accumulated. This means that you need to zero the gradients on each training pass or you'll retain gradients from previous training batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Optim is used for updating weights \n",
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optiize and learing rate , SGD means stochastic Gradeint DEscent\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights --- Parameter containing:\n",
      "tensor([[ 0.0063, -0.0339, -0.0045,  ...,  0.0325, -0.0283,  0.0308],\n",
      "        [-0.0283,  0.0074, -0.0045,  ...,  0.0283,  0.0225,  0.0079],\n",
      "        [ 0.0176, -0.0110,  0.0029,  ...,  0.0030,  0.0145, -0.0203],\n",
      "        ...,\n",
      "        [-0.0314, -0.0076, -0.0015,  ..., -0.0009, -0.0289, -0.0018],\n",
      "        [ 0.0331,  0.0221, -0.0091,  ..., -0.0302, -0.0179,  0.0240],\n",
      "        [-0.0171, -0.0100,  0.0104,  ...,  0.0086, -0.0341,  0.0174]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-9.1316e-05, -9.1316e-05, -9.1316e-05,  ..., -9.1316e-05,\n",
      "         -9.1316e-05, -9.1316e-05],\n",
      "        [-9.7919e-05, -9.7919e-05, -9.7919e-05,  ..., -9.7919e-05,\n",
      "         -9.7919e-05, -9.7919e-05],\n",
      "        ...,\n",
      "        [ 1.0838e-04,  1.0838e-04,  1.0838e-04,  ...,  1.0838e-04,\n",
      "          1.0838e-04,  1.0838e-04],\n",
      "        [ 2.6717e-05,  2.6717e-05,  2.6717e-05,  ...,  2.6717e-05,\n",
      "          2.6717e-05,  2.6717e-05],\n",
      "        [-5.5697e-05, -5.5697e-05, -5.5697e-05,  ..., -5.5697e-05,\n",
      "         -5.5697e-05, -5.5697e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights ---' , model[0].weight)\n",
    "images , lables = next(iter(trainloader))\n",
    "images = images.view(images.shape[0],-1)\n",
    "\n",
    "# Clear the Gradients , because gradients are accumulated from previous model and never erased\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward Pass\n",
    "output = model.forward(images)\n",
    "\n",
    "# Loss calculation \n",
    "loss = criterion(output , labels)\n",
    "\n",
    "# Backward pass to calculate gradients\n",
    "loss.backward()\n",
    "\n",
    "print('Gradient - ', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated weights -- Parameter containing:\n",
      "tensor([[ 0.0063, -0.0339, -0.0045,  ...,  0.0325, -0.0283,  0.0308],\n",
      "        [-0.0283,  0.0074, -0.0045,  ...,  0.0283,  0.0225,  0.0079],\n",
      "        [ 0.0176, -0.0110,  0.0029,  ...,  0.0030,  0.0145, -0.0203],\n",
      "        ...,\n",
      "        [-0.0314, -0.0076, -0.0015,  ..., -0.0009, -0.0289, -0.0018],\n",
      "        [ 0.0331,  0.0221, -0.0091,  ..., -0.0302, -0.0179,  0.0240],\n",
      "        [-0.0171, -0.0100,  0.0104,  ...,  0.0086, -0.0341,  0.0174]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Updat step and weights updated\n",
    "optimizer.step()\n",
    "print('updated weights --' , model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION  \n",
    "\n",
    "- Algorithm into a loop so we can go through all the images. one pass through the entire dataset is called an **epoch**. So here we're going to loop through trainloader to get our training batches. For each batch, we'll doing a training pass where we calculate the loss, do a backwards pass, and update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9752200104788677\n",
      "Training loss: 0.9168159902604149\n",
      "Training loss: 0.5470624945438238\n",
      "Training loss: 0.44533174986968926\n",
      "Training loss: 0.39591231764252505\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            # Flatten MNIST images into a 784 long vector\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # TODO: Training pass\n",
    "\n",
    "            loss = criterion(model.forward(images), labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        else:\n",
    "            print(f\"Training loss: {running_loss/len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.0635e-06, 1.4671e-03, 2.3314e-02, 3.3154e-02, 1.8511e-03, 3.6528e-04,\n",
      "         6.7920e-06, 6.3255e-01, 1.8814e-02, 2.8847e-01]])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADQdJREFUeJzt3X+oXPWZx/HPR21FTVFjMLkk2U23ylIRsXIRIWVJXFLdpRD7R0Pzh2Sx9PaPGi0UUQyagCzIUlsLQiGxsRFak0rTNWDZNgRBK0WMYqptbBPjbXM1JtYUG3/WJE//uCfLbbxzZnLmnDlz87xfEGbmPGfOeRz8zDkz3zP364gQgHzOaLsBAO0g/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkjprkDuzzeWEQMMiwr2s19eR3/b1tn9ve6/tO/rZFoDBctVr+22fKekPkpZJmpD0rKSVEfG7kudw5AcaNogj/9WS9kbEvoj4m6TNkpb3sT0AA9RP+OdL2j/l8USx7B/YHrO90/bOPvYFoGb9fOE33anFx07rI2K9pPUSp/3AMOnnyD8haeGUxwskvd5fOwAGpZ/wPyvpUtuftv1JSV+RtK2etgA0rfJpf0QctX2zpF9IOlPSxoj4bW2dAWhU5aG+SjvjMz/QuIFc5ANg5iL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqcpTdEuS7XFJRyQdk3Q0IkbraApA8/oKf2FpRPy5hu0AGCBO+4Gk+g1/SPql7edsj9XREIDB6Pe0f3FEvG77Yknbbb8cEU9OXaF4U+CNARgyjoh6NmSvk/RORHy7ZJ16dgago4hwL+tVPu23fZ7tT524L+kLkl6quj0Ag9XPaf9cST+zfWI7P46I/6ulKwCNq+20v6edJT3tP+us8vfYbvUmrV69urS+Zs2a0vr5559fed9vvPFGaf3uu+8urW/YsKHyvk9njZ/2A5jZCD+QFOEHkiL8QFKEH0iK8ANJMdTXo1mzZnWsPfDAA6XPXbZsWWl9ZGSkUk+nu6eeeqq0vnTp0tL68ePH62xnxmCoD0Apwg8kRfiBpAg/kBThB5Ii/EBShB9IinH+Ht10000daw8++OAAO6nXhx9+WFrvNlZ+xhnlx4+zzz77lHvq1SWXXFJa37dvX2P7HmaM8wMoRfiBpAg/kBThB5Ii/EBShB9IivADSTHO36OLLrqoY218fLz0ud3+NPdHH31UpaWeHD58uLS+ZMmS0nq3/7Ybb7yxtL5p06bSeplXX321tH7VVVeV1t9+++3K+57JGOcHUIrwA0kRfiApwg8kRfiBpAg/kBThB5LqOje07Y2SvijpUERcXiybLWmLpEWSxiWtiIi/NNdm+956662OtXnz5pU+t9vvznft2lWpp2FwwQUXNLbtbtcYZB3Hr0svR/4fSrr+pGV3SNoREZdK2lE8BjCDdA1/RDwp6eTLxJZLOnHp1iZJN9TcF4CGVf3MPzciDkhScXtxfS0BGISun/n7ZXtM0ljT+wFwaqoe+Q/aHpGk4vZQpxUjYn1EjEbEaMV9AWhA1fBvk7SquL9K0mP1tANgULqG3/Yjkn4t6V9tT9j+qqR7JS2zvUfSsuIxgBmE3/OjL93+Nv6iRYsqb3vLli2l9ZUrV1be9umM3/MDKEX4gaQIP5AU4QeSIvxAUoQfSKrxy3sxs11zzTWl9blz51bedrfpwdesWVN52+iOIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMU4P0rdddddpfVzzjmn8rZXr15dWu/2c2H0hyM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFOP8QuOyyy0rrCxcurLztnTt3ltavu+660vrSpUsr77ub2267rbT+wQcflNbffPPNyvvesWNHaf3o0aOVtz1TcOQHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaS6TtFte6OkL0o6FBGXF8vWSfqapBMDrXdGxM+77izpFN2zZ88ure/atau0Pn/+/Mr7fu2110rr3Xrr5/f6w+yee+4pra9du3ZAndSvzim6fyjp+mmWfzciriz+dQ0+gOHSNfwR8aSkwwPoBcAA9fOZ/2bbv7G90faFtXUEYCCqhv/7kj4j6UpJByTd12lF22O2d9ouv8gcwEBVCn9EHIyIYxFxXNIGSVeXrLs+IkYjYrRqkwDqVyn8tkemPPySpJfqaQfAoHT9Sa/tRyQtkTTH9oSktZKW2L5SUkgal/T1BnsE0ICu4/y17izpOH83K1asKK1v3rx5QJ3MLEeOHCmtP/roox1r993X8WsqSdLu3bsr9TQM6hznB3AaIvxAUoQfSIrwA0kRfiApwg8kxVDfEDj33HNL64sXL6687dtvv720fu2111betiS9++67pfVbbrmlY21iYqKvfe/fv7+0/vLLL/e1/ZmKoT4ApQg/kBThB5Ii/EBShB9IivADSRF+ICmm6B4C7733Xml9+/btlbd9xRVXlNb7Heffs2dPaf2hhx7qa/toDkd+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iKcf7TwJw5czrWbr311kb3ff/99ze6fTSHIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNV1nN/2QkkPS5on6bik9RHxPduzJW2RtEjSuKQVEfGX5lpFJ6tWrepYW7BgQV/bfuWVV0rrZdNgY7j1cuQ/KulbEfFZSddI+obtyyTdIWlHRFwqaUfxGMAM0TX8EXEgIp4v7h+RtFvSfEnLJW0qVtsk6YammgRQv1P6zG97kaTPSXpG0tyIOCBNvkFIurju5gA0p+dr+23PkvRTSd+MiL/aPU0HJttjksaqtQegKT0d+W1/QpPB/1FEbC0WH7Q9UtRHJB2a7rkRsT4iRiNitI6GAdSja/g9eYj/gaTdEfGdKaVtkk58zbxK0mP1twegKb2c9i+WdKOkF22/UCy7U9K9kn5i+6uS/iTpy820iG5WrFjR2Laffvrp0vr777/f2L7RrK7hj4hfSer0Af/f620HwKBwhR+QFOEHkiL8QFKEH0iK8ANJEX4gKf50N0pt3bq1+0qYkTjyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFL8nj+5vXv3ltYff/zxAXWCQePIDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJdR3nt71Q0sOS5kk6Lml9RHzP9jpJX5P0ZrHqnRHx86YaRTOeeOKJ0vqxY8cG1AkGrZeLfI5K+lZEPG/7U5Kes729qH03Ir7dXHsAmtI1/BFxQNKB4v4R27slzW+6MQDNOqXP/LYXSfqcpGeKRTfb/o3tjbYv7PCcMds7be/sq1MAteo5/LZnSfqppG9GxF8lfV/SZyRdqckzg/ume15ErI+I0YgYraFfADXpKfy2P6HJ4P8oIrZKUkQcjIhjEXFc0gZJVzfXJoC6dQ2/bUv6gaTdEfGdKctHpqz2JUkv1d8egKY4IspXsD8v6SlJL2pyqE+S7pS0UpOn/CFpXNLXiy8Hy7ZVvjMAfYsI97Je1/DXifADzes1/FzhByRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSGrQU3T/WdIfpzyeUywbRsPa27D2JdFbVXX29s+9rjjQ3/N/bOf2zmH9237D2tuw9iXRW1Vt9cZpP5AU4QeSajv861vef5lh7W1Y+5LorapWemv1Mz+A9rR95AfQklbCb/t627+3vdf2HW300Intcdsv2n6h7SnGimnQDtl+acqy2ba3295T3E47TVpLva2z/Vrx2r1g+z9b6m2h7Sds77b9W9u3Fstbfe1K+mrldRv4ab/tMyX9QdIySROSnpW0MiJ+N9BGOrA9Lmk0IlofE7b9b5LekfRwRFxeLPsfSYcj4t7ijfPCiLh9SHpbJ+mdtmduLiaUGZk6s7SkGyT9l1p87Ur6WqEWXrc2jvxXS9obEfsi4m+SNkta3kIfQy8inpR0+KTFyyVtKu5v0uT/PAPXobehEBEHIuL54v4RSSdmlm71tSvpqxVthH++pP1THk9ouKb8Dkm/tP2c7bG2m5nG3BMzIxW3F7fcz8m6ztw8SCfNLD00r12VGa/r1kb4p5tNZJiGHBZHxFWS/kPSN4rTW/Smp5mbB2WamaWHQtUZr+vWRvgnJC2c8niBpNdb6GNaEfF6cXtI0s80fLMPHzwxSWpxe6jlfv7fMM3cPN3M0hqC126YZrxuI/zPSrrU9qdtf1LSVyRta6GPj7F9XvFFjGyfJ+kLGr7Zh7dJWlXcXyXpsRZ7+QfDMnNzp5ml1fJrN2wzXrdykU8xlHG/pDMlbYyI/x54E9Ow/S+aPNpLk794/HGbvdl+RNISTf7q66CktZL+V9JPJP2TpD9J+nJEDPyLtw69LdEpztzcUG+dZpZ+Ri2+dnXOeF1LP1zhB+TEFX5AUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5L6O3FS4KNxA3jjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r');\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "    \n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "print(ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
