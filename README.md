# Deep-Learning-Tutorial 
It covers Assignments done in Deep Learning Course in [Indraprastha Institute of Information Technology, Delhi (IIITD)](https://www.iiitd.ac.in/) and Udacity NanoDegree [Intro to Deep Learning uisng Pytorch](https://www.udacity.com/course/deep-learning-pytorch--ud188). 

## Table Of Contents of Deep Learning Assignments
| S.NO     | TOPICS  | PROJECT  NAME    | 
| :-----------------------------------------|    :-----------------------------------:   |  ---: | 
| 01.     |**PTA for AND,OR,NOT and XOR** and **Madeline Implementation** from scratch | [Implementing PTA and Madeline](IIIT_Delhi_assignments/001_Implementing_Perceptron_Training_algorithm_and_Madeline_algorithm/)  | 
| 02.     | From **scratch** implementation of **Back Propagation** with optimizers **Momentum, NAG, AdaGrad, RMSProp, Adam** and initializations **He, Xavier** and Regularization using **L1, L2 and Dropout**. No Deep Learning library used.| [Backpropagation Optimizers Regularization from scratch](IIIT_Delhi_assignments/002_Backpropagation_optimizers_and_regularization_from_scratch/)  | 
| 03.     |**CNN** Implementation | [Convolutional Neural Networks](IIIT_Delhi_assignments/003_Convolutional_Neural_networks/)  | 
| 04.     | Implemented Papers [**Show, Attend and Tell: Neural Image Caption Generation with Visual Attention**](https://arxiv.org/pdf/1502.03044.pdf) and [**Interactive Attention Networks for Aspect-Level Sentiment Classification**](https://arxiv.org/pdf/1709.00893.pdf)| [Attention models](IIIT_Delhi_assignments/004_Attention_models/)  | 

## Table Of Contents of Udacity Nanodegree course

|S.NO|                               TOPICS                                                 | PROJECT NAME      |
|----|--------------------------------------------------------------------------------------|-------------------|
|01. |Implementing **Gradient Descent** over a set of random data          |[1_GradientDescent](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/1_GradientDescent.ipynb)      |
|02. |Simple Neural Network and common functions like **tensor.view() tensor.reshape()  tensor.shape tensor.rand**      |[2_Simple Neural Network and Random Functions](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/2_Simple%20Neural%20Network%20and%20Random%20Functions.ipynb)     |                                          
|03. |Creating **Multi-Layer Neural Network** and converting **numpy array to tensors**     |[3_Multi Layer Neural Networks & numpy to torch](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/3_Multi%20Layer%20Neural%20Networks%20%26%20numpy%20to%20torch.ipynb)  |
|04. | **Digit Classification** dataset using softmax and matrix multiplication(NO TRAINING) |[4_Digit Classification with Softmax (NO TRAINING)](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/4_Digit%20Classification%20with%20Softmax%20(%20NO%20TRAINING).ipynb)  |
|05. | **pytorch nn module** for complex neural networks , using **torch.nn.functional**      |[5_Building networks with Pytorch - nn Module](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/5_Building%20networks%20with%20Pytorch%20-%20nn%20Module.ipynb)       |
|06. |other Activations , Neural Network using **Relu** and **nn.Sequential** , Changing weights and biases , using **OrderedDict** to name individual layers       |[6_Relu Activation neural network and nn.Sequential](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/6_Relu%20Activation%20neural%20network%20and%20nn.Sequential.ipynb)  |
|07. |**Training** network over Digit Classification  - **loss calculation-criterion** , **Autograd** , update weights using **Pytorch -optim**      |[7_Training Neural Network](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/7_Training%20Neural%20Network.ipynb)|
|08. |Training neural network to classify **Fashion-MNIST**      | [8_Classifying Fashion-MNIST](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/8_Classifying%20Fashion-MNIST.ipynb)|
|09. |Test over **Test data** , **overfitting**, regularization using **Dropout** and **Accuracy Calculation** |[9_Fashion MNIST - INFERENCE AND VALIDATION](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/9_Fashion%20MNIST%20-%20INFERENCE%20AND%20VALIDATION.ipynb)    |
|10. |Saving models using **state_dict** and training later on |[_10_Saving and Loading Models](https://github.com/AkankshaShrimal/Pytorch-Learning/tree/master/_10_Saving%20and%20Loading%20models)    |
|11. |Making **filters** and visualising CNN |[convulution-Neural-Network](https://github.com/AkankshaShrimal/Pytorch-Learning/tree/master/convulution-Neural-Network)    |
|12. |**Transfer learning**|[12_CATS_VS_DOG_CLASSIFICATION_TRANSFER_LEARNING](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/12_CATS_VS_DOG_CLASSIFICATION_TRANSFER_LEARNING.ipynb)    |
|13. |**STYLE TRANSFER**|[Style_Transfer](https://github.com/AkankshaShrimal/Pytorch-Learning/blob/master/STYLE%20TRANSFER/Style_Transfer.ipynb)    |
